{
  
    
        "post0": {
            "title": "The masked analyst",
            "content": "Background . We are going to review the paper Effectiveness of Surgical and Cotton Masks in Blocking SARS–CoV-2: A Controlled Comparison in 4 Patients with a focus on the interpretation of the data. . . Warning: although we are going to nitpick the small report quite a lot, this is in no way an attack on the authors or their work. In fact I consider even this minute studies quite important given the current pandemic. Furthermore: there have been comments by several people about methodological mistakes in the study. I am in no position to comment on those. In fact I want to stress out that I am in no position of advising anybody on such a delicate topic except, maybe on how to avoid some common mistakes . Apart for a personal interest in the topic of masks for source control of the COVID-19 pandemic, the two main reasons that make this paper a good subject of examination are that . the study is so small that we can easily rewrite the whole dataset and tear it apart at our convenience | it highlights a number of common pitfalls when interpreting/analysing data that any person working with data should be aware of | The goal of the paper, as stated by the authors themselves is . To evaluate the effectiveness of surgical and cotton masks in filtering SARS–CoV-2. . In order to do that, they selected 4 patients with COVID-19 and had them cough on a petri dish kept 20 cm away, first without a mask, then with a surgical mask, then with a cotton mask, and finally a second time without a mask. After that, both the petri dishes and the masks were examined to measure the concentration of virus particles. . The data gathered is all contained in this small table . . Reproducing the analysis . As I said, the amount of data gathered is so small that we can easily rewrite it by hand and peruse it. Since I am less interested in the mask surfaces measurements, I will leave those numbers out, especially considering that they look quite bizarre (there are a number of possible explanations for the inner side of the masks having way lower concentrations of virus particles than the outer side, but they are way beyond my understanding and scope for this post). . #collapse naso_pha_swab = [7.68, 5.42, 5.98, 3.57] saliva_swab = [4.29, 2.59, 5.91, 3.51] control1 = [3.53, 2.14, 2.52, np.nan] surgical_mask = [3.26, 1.8, 2.21, np.nan] cotton_mask = [2.27, np.nan, 1.42, np.nan] control2 = [3.23, 2.06, 2.64, 2.44] data_df = pd.DataFrame(data=[naso_pha_swab, saliva_swab, control1, control2, surgical_mask, cotton_mask], columns=[&#39;patient1&#39;, &#39;patient2&#39;, &#39;patient3&#39;, &#39;patient4&#39;], index=[&#39;np_swab&#39;, &#39;saliva_swab&#39;, &#39;control_before&#39;, &#39;control_after&#39;, &#39;surgical_mask&#39;, &#39;cotton_mask&#39;]).T data_df . . np_swab saliva_swab control_before control_after surgical_mask cotton_mask . patient1 7.68 | 4.29 | 3.53 | 3.23 | 3.26 | 2.27 | . patient2 5.42 | 2.59 | 2.14 | 2.06 | 1.80 | NaN | . patient3 5.98 | 5.91 | 2.52 | 2.64 | 2.21 | 1.42 | . patient4 3.57 | 3.51 | NaN | 2.44 | NaN | NaN | . Problem 1: Basic sanity check . There is very little in terms of description of how the data analysis has been performed. This is what I can find in the paper. . The median viral loads of nasopharyngeal and saliva samples from the 4 participants were 5.66 log copies/mL and 4.00 log copies/mL, respectively. The median viral loads after coughs without a mask, with a surgical mask, and with a cotton mask were 2.56 log copies/mL, 2.42 log copies/mL, and 1.85 log copies/mL, respectively. . Unfortunately, if we try and reproduce those numbers we get something very different . data_df.median().round(2) . np_swab 5.70 saliva_swab 3.90 control_before 2.52 control_after 2.54 surgical_mask 2.21 cotton_mask 1.84 dtype: float64 . Solution: read the comments section . Reading the comments section of the paper, we discover that not only the authors meant mean, rather than median, but there is also a typo in the average control viral load. This is what they state the paragraph above should read: . The mean viral loads of nasopharyngeal and saliva samples from 4 participants were 5.66 log copies/mL and 4.00 log copies/mL, respectively, when we did calculate not detectable values. The mean viral loads after coughs without a mask, with a surgical mask, and with a cotton mask were 2.65 log copies/mL, 2.42 log copies/mL, and 1.85 log copies/ml, respectively, when we did not calculate not detectable values . If we check the mean rather than median, we get way closer numbers. I am still a bit uncertain about the saliva swabs mean viral load, but the other differences can definitely be attributed to rounding problems . data_df.mean().round(2) . np_swab 5.66 saliva_swab 4.07 control_before 2.73 control_after 2.59 surgical_mask 2.42 cotton_mask 1.84 dtype: float64 . Taking the average of the two control means, we also get a number which is quite close to the stated control viral load. . def get_control(df): return( df[&#39;control_before&#39;] + df[&#39;control_after&#39;]) / 2 get_control(data_df.mean().round(2)).mean() . 2.66 . . Important: Always double check your numbers and do frequent sanity checks . Aside: Median or Mean? . Although after the authors&#39; corrections the topic is not strictly relevant to our analysis, how can we decide whether to pick the median or the mean as a centrality measure? . The quick answer is that it is almost always a good idea to use the median rather than the mean, as it is way more robust to outliers (for a more detailed explanation you can check, for example, this post). The reason why we tend to use the mean is that it is mathematically well behaved and efficient to compute, but nowadays we can get around that with brute computational power and get something which is more robust. . The main exception to this rule is when you have very small samples, especially if you are measuring integers. The reason being that in this situation the median can jump around quite a bit. Let&#39;s run a small experiment. Here is a population of 20,000 integeres normally distributed (with standard deviation 20) around a mean of 100. . #collapse population = np.random.normal(100, 20, 20000).round().astype(int) plt.subplots(figsize=(10, 4)) plt.hist(population, bins=50)[-1] plt.axvline(population.mean(), color=&#39;k&#39;, linestyle = &#39;--&#39;); . . If we draw 1000 random samples of size 4 from the population, we can see that the medians of the samples are a bit more spread out than the means (and have a higher standard deviation). This means that picking the median we are more likely to make of being further away from the true population statistics. . #collapse samples = [np.random.choice(population, replace=False, size=4) for _ in range(1000)] medians = [np.median(x) for x in samples] means = [np.mean(x) for x in samples] plt.hist(means, bins=100, density=True, alpha=.7, label=f&#39;means std: {round(np.std(means), 3)}&#39;)[-1] plt.hist(medians, bins=100, density=True, alpha=.7, label=f&#39;medians std: {round(np.std(medians), 3)}&#39;)[-1] plt.legend(); . . . Important: prefer the median over the mean, except when dealing with very small samples of integers. . In fact, this is exactly the situation of the paper we are looking at (the reason will be probably clearer when we get to the discussion on the units of viral loads). . Conclusions (of the paper) . With those numbers we have seen above in mind, the authors reach the conclusion that surgical and cotton masks are not effective at controlling the spread of COVID-19: . Neither surgical nor cotton masks effectively filtered SARS–CoV-2 during coughs by infected patients [...] In conclusion, both surgical and cotton masks seem to be ineffective in preventing the dissemination of SARS–CoV-2 from the coughs of patients with COVID-19 to the environment and external mask surface. . Although they do not specify any detail, we can see that the difference in percentage of the viral load with and without a mask is roughly 9% and 30% for surgical and cotton masks respectively, which seem to support that the conclusion that these kind of masks are barely useful. . def get_test(df): return(df[[&#39;surgical_mask&#39;, &#39;cotton_mask&#39;]]) def get_difference(df, pct=True): return (get_control(df) - get_test(df).T) / get_control(df) if pct else (get_control(df) - get_test(df).T) get_difference(data_df.mean().round(2)) . surgical_mask 0.090226 cotton_mask 0.308271 dtype: float64 . End of the story then? . Not exactly. . Problem n.2: ND != NA . As I am sure everybody who has dabbed a bit with data science knows, one of the common themes when doing exploratory data analysis and preparing your dataset is dealing (and inputing) missing values. There are different ways of dealing with them, but the most common ones are: . input some centrality measure to fill the missing values (normally you want to use the median for continuous variable and the mode for categorical values) | build a predictive model to fill the gaps and use the predictions insted | throw away the missing values altogether | The last one is usually the safest option, and it is what we have done so far (when we computed the mean the default behaviour is simply ignore missing values), and I assume this is what the authors mean by . when we did not calculate not detectable values . If you check the table at the beginning of the post, though, you will see that ND stands, in fact, for &quot;not detected&quot;. . The problem here is that &quot;not detected&quot; does not mean that the value is missing:it means that it is too low for us to measure it. This means, in principle, that, depending on how sensitive the measure is, it could be anywhere between 0 and 1.42 (which is the smallest value measured in the table). Let&#39;s see what happens if we consider 1.41, which is the most conservative value for the detectability threshold. . data_df.fillna(1.41).mean().round(2) . np_swab 5.66 saliva_swab 4.07 control_before 2.40 control_after 2.59 surgical_mask 2.17 cotton_mask 1.63 dtype: float64 . get_control(data_df.fillna(1.41).mean().round(2)) . 2.495 . get_difference(data_df.fillna(1.41).mean().round(2)) . surgical_mask 0.130261 cotton_mask 0.346693 dtype: float64 . As we can see, even if the end result still seems to indicate that cotton and surgical masks are not particularly effective at source control, the numbers (especially for surgical masks) have changed quite a bit. . . Important: pay particular attention at the semantics of unusual values. This includes missing values and outliers (for example, it is not uncommon to use &quot;magic&quot; dates or numbers to indicate a missing value or something specific about a piece of data). If you do not, it might completely throw off your analysis . Problem n.3: wrong test . Another problem of the approach we have used so far is that the authors are (presumably) comparing the average viral loads of the same group with and without the masks. This (i.e. evaluating the differences of the averages) is the same as considering the test and control groups as independent, which is certainly not the case here as it&#39;s the same patients being used as test and control groups. A more appropriate idea is to instead consider the differences with and without the masks for each patient independently and then averaging those differences. In other words, it is better to compute the mean of the differences rather than the difference of the mean. This is particularly important when there is a lot of variance in your test population. It is hard to tell in this case, but looking at the characteristic of the patients, they are far from a homogeneous group. Furthermore, there is really no reason not to use the appropriate test, so let&#39;s see what happens. . get_difference(data_df.fillna(1.41)).T . surgical_mask cotton_mask . patient1 0.035503 | 0.328402 | . patient2 0.142857 | 0.328571 | . patient3 0.143411 | 0.449612 | . patient4 0.267532 | 0.267532 | . get_difference(data_df.fillna(1.41)).T.mean() . surgical_mask 0.147326 cotton_mask 0.343530 dtype: float64 . In this case not much has changed (except that surgical masks look slightly better than before). . . Important: check your assumptions of indpendence betweeen the test and control groups (you have a test and control group, right?) . Huge Problem n.4: watch your logs! . If we look carefully at the data table from the paper, we notice that there is no unit to tell us what are the numbers we are measuring. This can be found in the text though (and it is probably obvious to anyone who is used to deal with viral loads): . The median viral loads of nasopharyngeal and saliva samples from the 4 participants were 5.66 log copies/mL and 4.00 log copies/mL, respectively. . Here we notice a red flag:log copies/mL seems to indicate that we are dealing with a logarithmic scale. A quick googling can confirm that: those numbers are the base 10 logarithm of the number of viral copies per milliliter. This is quite common when you are dealing with concentrations (the same thing happens, for example with pH, which is a measure of concentration of ions) as the numbers tend to be quite large and we are more interested in the order of magnitude rather than the magnitude (i.e. the actual numbers) itself. This causes a massive problem, though: when we take the mean of two logarithms, we are actually taking the geometric mean of the underlying quantities, and if we consider the difference of two logarithms, we are actually looking at the ratio of the quantities. . Just in case you need a reminder for the properties of logarithms, what we are saying is that: . $$ ( log x + log y) / 2 = log { sqrt {xy} } $$ . How big of a problem this is? . Consider this: a difference between two viral loads of 1 log copies/mL means that the larger load contains 10 times more viral particles than the smaller ones. If the two viral loads were 3 and 4 log copies/mL we would be treating a 90% difference as if it were a 25% difference. And if the two viral loads are 9 and 10 log copies/mL, we would be treating a 90% difference as if it were a 10% difference! . As a mathematician, my instinct would be to rewrite the formulas using the properties of the logarithms (which can be a pain or not necessarily possible), but in fact, especially when the range of values is relatively small, the easiest way to proceed is to &quot;unroll&quot; the logarithms and redo our computations with the actual quantities: . get_difference((10 ** data_df.fillna(1.41)), pct=False).T . surgical_mask cotton_mask . patient1 723.641748 | 2357.133893 | . patient2 63.331160 | 100.722936 | . patient3 221.642467 | 357.520797 | . patient4 124.859456 | 124.859456 | . get_difference((10 ** data_df.fillna(1.41)), pct=False).T.mean() . surgical_mask 283.368708 cotton_mask 735.059271 dtype: float64 . These are the average number of viral particles filtered. How does this compare with the numbers computed before we unrolled the logarithms? It&#39;s roughly 100 times larger. . 10 ** get_difference(data_df.fillna(1.41), pct=False).T.mean() . surgical_mask 2.119581 cotton_mask 7.391796 dtype: float64 . So, all in al,l once we have fixed all the problems these are the filtering powers of surgical and cotton masks under our (conservative) look like this: . get_difference((10 ** data_df.fillna(1.41)), pct=True).T.mean() . surgical_mask 0.548049 cotton_mask 0.871057 dtype: float64 . This is a very different result from what we have obtained above as it seems to suggest that cotton masks are actually quite good at reducing the viral load spread (and remember that we are talking about coughing and being 20 cm apart, in reality this might have huge impact on the effectivness of social distancing). . . Important: always check the units and be very cautious when using a logarithmic quantity. Try to &quot;unroll&quot; the log before doing your computations if the range is not too large. . So far I hope you are convinced that the conclusions reached in the paper is, at the very least, not that clear cut (and if you ask me in fact it&#39;s the exact opposite of what the data is actually saying). . But let&#39;s address a further criticism that is very often used to dismiss small studies. . Statistical significance . &quot;Surely an experiment with N = 4 is not statistically significant&quot; or something along those lines is a sentence that I hear far too often when evaluating the effort needed to measure an imporant quantity. Well, it turns out that until you start designing experiments and actually look at the numbers, we don&#39;t really have an intuitive feel for sample sizes. . Let&#39;s see what we can do here. The first and most important problem we have is that the objective of the study is actually not well defined. . To evaluate the effectiveness of surgical and cotton masks in filtering SARS–CoV-2. . As data people we should always make sure that the question we are trying to answer is well defined from a quantitative point of view, and this particular one is not (what does &quot;effective&quot; means in this context)? Furhtermore, the experiment is, not designed to test how effective masks are, for example, at filtering the virus in case of people, talking, or sneezing, or even just breathing, which would be interesting for advising policies in this case. . Keeping in mind that we are deviating from the original objective of the study, let&#39;s see if we can formulate some question that we can try and answer with the data available. . . Warning: let me state this clearly. In general, fishing for questions after the experiment is a very bad idea and it is not how you design an experiment. This is just an exercise in measuring what can be achieved with small samples and would give us a good idea of how to design a proper study . These are (by patient) the reductions of viral loads in percentage between our test and control conditions: . eff_pcts = get_difference((10 ** data_df.fillna(1.41))).T ; eff_pcts . surgical_mask cotton_mask . patient1 0.284524 | 0.926786 | . patient2 0.500931 | 0.796689 | . patient3 0.577459 | 0.931472 | . patient4 0.829282 | 0.829282 | . Let&#39;s start with a very simple question: are masks better than nothing at reducing the viral load (under the test conditions)? . To appease the frequentist readers, let&#39;s do a very basic t-test. We will do it by hand, rather than using a specific library, except for the computation of the critical thresholds. . Our question translates into &quot;is the filtered percentage of the viral load statistically greater than 0?&quot; Here is is how we compute the t stats. . means = eff_pcts.mean() ### Notice: this is the standard error for N = 4 std_errors = eff_pcts.std() / 2 t_stats = means / std_errors . We use scipy to find the critical thresholds for $ alpha$ at 0.0625, 0.05, 0.01, and 0.005. In other word we compute the value above which the t-stats need to be in order for the p-value to be below the different $ alpha$ levels and for us to reject the null hypothesis that the test condition is not better than the control condition. . Why and whether this is a good idea is a very long and out of scope discussion, but this is a classical and radicated method of testing hypothesis. Except for the 0.0625 one which I will explain later, the values of $ alpha$ are some of the commonly used ones in science, with 0.05 being by far the most common. . from scipy.stats.distributions import t αs = [0.0625, 0.05, 0.01, 0.005] df = 3 for α in αs: print(f&#39;{(α) * 100}%: {t.ppf(1 - α, df)}&#39;) . 6.25%: 2.113086729236424 5.0%: 2.3533634348018264 1.0%: 4.540702858698419 0.5%: 5.84090929975643 . So are the t statistics higher than those values? Let&#39;s see . t_stats . surgical_mask 4.875605 cotton_mask 25.473360 dtype: float64 . It turns out that both cotton and surgical masks are better than no mask in a strongly statistically significant way. Cotton masks in particular have a p-value which is way lower than the strictest normally used significance thresholds. . In retrospect, though, the results is not surprising: given what we know about the virus transmission it is (or should be) common sense that putting a physical barrier in front of your mount will filter at least minimally better than not putting it. And in fact I claim that this should have been our null hypothesis in the first place, but let&#39;s not delve into that. Let&#39;s assume that in order for masks to be effective, they need to be filtering at least 80% of the viral load. Can we say that? . means = (eff_pcts - .8).mean() std_errors = eff_pcts.std() / 2 # Let&#39;s directly see the p-vaues rather than the t-stats (means / std_errors).apply(lambda x: 1 - t.cdf(x, df=df)) . surgical_mask 0.944593 cotton_mask 0.064624 dtype: float64 . Not surprisingly, the answer is a resounding no for surgical masks (but at this point they were not even in the game anymore). . What about cotton masks? We have a p-value of 6.5%. This is above all the thresholds so in principle we cannot reject the null hypothesis, but it would be considered &quot;at the border of significance&quot; if we were to submit a paper. . . Important: Even a very small sample can be statistically significant. In fact samples that are too large might have worse descriptive power, as they might amplify any sampling bias we have. . Let&#39;s think for a second about the values we have just seen. A p-value of 6.5% means that the average cotton mask could, in principle, not have a filtering power better than 80% as the p-value is not lower than the accepted 0.05 threshold (or any of the other thresholds we have looked at, for that matters). . So we should not advice wearing cotton masks, right? Well not so fast: the p-value can be thought as the fals positive rate. This means that if we see an effect (like we do in this case, as the average in our sample is over 80%) the p-value is the probability of that effect being a statistical fluke. In other words, there is a 93.5% probability that the effect we are seeing (the average filtering power is higher than 80%) is real. . Is this enough? It depends. In particular it depends on the cost of making a mistake. In most business cases, and when the cost of getting that wrong is very low, we can accept a false positive risk way higher than the standard 5% used in science. . . Important: There is nothing magic about the 5% statistical significance threshold. If you are doing hypothesis testing, pick a threshold that makes sense from a business perspective and consider the costs of making a mistake. . Let&#39;s do one last test before looking at a different trick. The question we want to answer is: are the averages filtering power of masks significantly better than the lowest values we have observed (with a weird significance threshold of 6.25%)? . means = (eff_pcts - eff_pcts.min()).mean() ### Notice: this is the standard error for N = 4 std_errors = eff_pcts.std() / 2 t_stats = means / std_errors cohen_d = t_stats / 2 t_stats.apply(lambda x: 1 - t.cdf(x, df=df)) . surgical_mask 0.050409 cotton_mask 0.058960 dtype: float64 . Under this conditions we can reject the null hypothesis, so we can tell that the mean filtering power higher than the smallest number observed with a probability of at least 93.75% (1 - $ alpha$). Let&#39;s keep this in mind and see as later we will compare it to another technique. . . Warning: doing multiple experiments with the same observations and the same $ alpha$ values is in general a very bad idea. Normally we would need to apply something like the Bonferroni correction or similar tricks. In this case, though, we are not really doing multiple experiments, but rather checking the same thing with different thresholds and probing for statistical significance, which we could have done analytically in a single go. In any case, please always be extra cautious with p-values. . A touch of Bayes . Hypothesis testing is all fun and good, but what if we wanted to answer a question like &quot;how much viral load on average a cotton mask filters&quot;? . At this point we are out of the world of yes/no questions and we are into the world of measurement. In a certain Bayesian way of thinking, we could say that measuring something means reducing our uncertainty about the real value of that something. A good measurement consists in a range of possible values for the things we are measuring (since no measurement is without error) and a probability of the measured value to fall into that range. Essentially, the smaller the range (everything else being the same), the less our uncertainty. Measuring something, thus, means reducing the range of values we are confident enough our true value falls into. . One often overlooked aspect of measuring stuff (that with this very broad definition might also mean producing a report) is that each measurement has cost attached and a steeply diminishing value. . For example, it is extremely easy to measure my height with a .5 meters precision. Still easy with a 10 cm precision. Reasonably doable within a 1 cm. Virtually impossible and probably very expensive within a 1 $ mu m$. Not to mention completely useless. . For this very reason, when we have a lot of uncertainty about a certain quantity, a very small number of measurement can take us a very long way. . In this perspective, since a priori we know nothing about the actual value of the filtering power of cotton masks for viral loads of SARS–CoV-2, we can expect to gain a lot of insight even with the very small number of measurments we have. . Let&#39;s see this in practice. This is what we have measured (with the conservative assumption we are keeping about non detectable values). . eff_pcts = get_difference((10 ** data_df.fillna(1.41))).T.sort_values(&#39;cotton_mask&#39;) eff_pcts.sort_values(&#39;cotton_mask&#39;).cotton_mask . patient2 0.796689 patient4 0.829282 patient1 0.926786 patient3 0.931472 Name: cotton_mask, dtype: float64 . Once again, although it is not evident, &quot;how much viral load on average a cotton mask filters&quot; is not particularly well defined from a quantitative point of view. Let&#39;s rephrase it as &quot;what is the median percentage of virus load filtered by cotton masks?&quot;. . Now, that&#39;s different. One of the hidden assumptions that we used during our hypotheses testing, which is almost inescapable, is that the sample we chose is not biased. In other words, we assume have selected our patients at random. This is essentially never true, and the bigger the sample, the worst the bias will be, but for the sake of argument, let&#39;s assume that the effect of sampling bias is negligible. In this case each measurement has a 50% probability of being below the median (by definition of median itself). With a bit of combinatorics, we can compute the probability of being higher than our highest measured value, our second highest value and so on. . np.array([1/16, 4/16, 6/16, 4/16, 1/16]).cumsum()[:-1] . array([0.0625, 0.3125, 0.6875, 0.9375]) . What we are saying is that the median filtering power of cotton masks has a 6.25% chance of being above 93%, a 31.25% of being above 92.7%, etc. . In other word, with only 4 values we can assert that the median is higher than the smallest measured value with 93.75% probability. And this is true no matter how the values of filtering powers are distributed. . If we add some very common assumptions that we have used under the hood in our t-tests (namely that the median and the mean are the same), we can say exactly the same for the mean. . The combinatorics behind it are beyond the scope of this post (but not complicated), but as a general rule, if we sample (measure) N values from any distribution, the probability that the median of the population (i.e. the &quot;real&quot; median) is higher than the smallest value we have measured is $$ 1 - frac {1} {2 ^ N}$$ . Notice that this is very close to the result we have obtained with the last t-test (so I hope now you understand the $ alpha$ value of 0.0625), but is stronger, since it is making fewer assumptions on the population and it only requires (at most) pen and paper and a quick calculation. . . Important: when uncertainty is large, you can get a lot of mileage from a very small sample. . Quick power analysis . There is one last aspect that we have not eviscerated yet. Let&#39;s consider once again our t-test of significance for cotton masks being more than 80% effective on average. . We already know that the p-value is above the $ alpha$ value of 0.05, so we cannot reject the null hypothesis. But does this mean that we have to reject the test hypotesis? . This is where the power come into play (or rather 1 minus the statistical power of the experiment). . Like $ alpha$ is the acceptable risk of a false positive, there is an analogous $ beta$, which is the acceptable risk of a false negative. For some arbitrary historical reason, like we usually consider $ alpha$ to be 0.05, we consider $ beta$ to be 0.2. So the usually acceptable power of an experiment tends to be chosen as 1 - $ beta$, or 0.8. This means that in case we cannot reject the null hypothesis we want the probability of the null hypothesis being true at least 80%. . The statistical power is not easy to compute manually, but can it done analytically for a t-test, so we will use the statsmodels library to do so. This works allows us to fix 3 values among power, the number of observations (the parameter nobs), the chosen $ alpha$ and the effect size (long story short, in the case of the t-test is the t statistic divided by the square root of the number of observations) in order to obtain the remaining one. . What&#39;s the power of our t-test? . means = (eff_pcts - .8).mean() ### Notice: this is the standard error for N = 4 std_errors = eff_pcts.std() / 2 t_stats = means / std_errors cohen_d = t_stats / 2 t_stats.apply(lambda x: 1 - t.cdf(x, df=df)) from statsmodels.stats.power import TTestPower TTestPower().solve_power(effect_size=cohen_d.cotton_mask, power=None, nobs=4, alpha=0.05, alternative=&#39;larger&#39;) . 0.48376788050332065 . A power of 48.4% (way below the acceptable 80% threshold) means that although we cannot reject the null hypothesis, there is still a 52% risk of being in presence of a false negative, which is not acceptable. So we cannot formally reject the test hypothesis either. . We have gained a new piece of information with our experiment, though: we are now able to guess the expected effect size if we were to repeat the experiment. And we can plug this into the power analysis to find out how many patients do we need to test in order to have an acceptable statistical power and confidence. . TTestPower().solve_power(effect_size=cohen_d.cotton_mask, power=.8, nobs=None, alpha=0.05, alternative=&#39;larger&#39;) . 7.284382863086592 . What this is telling us is that the difference between what we have observed for cotton masks and a filtering power of 80% of the viral load is so strong that we only need 8 people to design a new experiment that would give us a reasonable opportunity of either rejecting the null hypothesis with 95% oconfidence or rejecting the test hypothesis with 80% confidence. . As menitoned above: we tend not to have a good intuition of what good sample sizes are. . . Important: a very small and potentially quick study can help a lot in designing a proper statistically sound experiment. This is particularly useful for A/B testing, for example .",
            "url": "https://datacasual.com/data-analysis/covid19/2020/05/07/masked-analyst.html",
            "relUrl": "/data-analysis/covid19/2020/05/07/masked-analyst.html",
            "date": " • May 7, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Palle cubiche (minipost)",
            "content": "In maniera più o meno legittima, in tempi di pandemia chiunque abbia avuto un minimo di infarinatura statistica (me compreso) si è dilettato a fare modelli di evoluzione del contagio. Come data scientist, e il mio passato da matematico aiuta, ho imparato che una delle cose più importanti quando si produce un modello è cercare in tutti i modi di trovarne i limiti e comunicare le possibili fonti di errore. Tutti i modelli sono sbagliati, e non preoccuparsi delle conseguenze di questi errori, può avere e spesso ha effetti catastrofici (ci sono decine di esempi, soprattutto con gli algoritmi più sofisticati, ma questo è un discorso per una lunga serie di post). . Particolarmente grave, quindi, quando un organo ufficiale si vanta a sproposito di un proprio modello, come in questo caso . To better visualize observed data, we also continually update a curve-fitting exercise to summarize COVID-19&#39;s observed trajectory. Particularly with irregular data, curve fitting can improve data visualization. As shown, IHME&#39;s mortality curves have matched the data fairly well. pic.twitter.com/NtJcOdA98R . &mdash; CEA (@WhiteHouseCEA) May 5, 2020 L’account del tweet (che per i non anglofoni essenzialmente dice che grazie alle nuove informazioni ottenute su COVID hanno costruito un “modello cubico” che funziona molto bene e che, come implica la figura, può essere usato per predirre l’andamento dell’epidemia negli USA) appartiene al “Council of Economic Advisers” della Casa Bianca, un organo ufficiale del governo degli USA. . A molti è saltato subito agli occhi che il “modello cubico” sembra non essere altro che un fitting polinomiale di terzo grado fatto in pochi secondi con Excel (qui, ad esempio il commento di Nate Silver, tanto per appellarsi all’autorità) . Like this took me 45 seconds and it seems to match the description of the &quot;cubic model&quot; quite well. pic.twitter.com/s91O6CTkw1 . &mdash; Nate Silver (@NateSilver538) May 5, 2020 Ma il problema non è nemmeno tanto l’utilizzo di un modello semplice. Ma che il modello è fatto ad arte per mostrare che l’epidemia è quasi finita e quindi è il momento di riaprire tutto. . Che problemi ci sono con il nostro “modello cubico”? . Prima di tutto utilizza come unico fattore predittivo del numero di morti giornaliero… la data. La cosa va anche bene quando si vuole mostrare cosa succederà nel breve termine se niente cambia nell’andamento attuale, ma ha un valore predittivo molto debole e non può essere utilizzato per predire un cambio di andamento (questo, ad esempio, è un errore che ho visto commettere a fin troppi matematici a inizio epidemia, nel tentare di capire quando sarebbe arrivato “il picco” o, per i più raffinati, “il flesso”; purtroppo sapere cos’è un’esponenziale o un modello logistico non attrezza a fare previsioni in pratica). . | Secondo questo modello, tra una settimana o poco più si arriva a zero contagi negli USA. Questo è il messaggio che si vuole far passare, ma è quanto meno molto poco probabile . | Se non fosse stato tagliato ad arte, lo stesso modello ci dice che verso inizio dicembre l’intera popolazione mondiale è morta di COVID e non ce ne siamo accorti . | Sempre estendendo il nostro “modello cubico”, questa volta nel futuro, realizziamo che intorno al 20 maggio i morti iniziano a tornare in vita in numeri sempre più abbondanti . | Per capire cosa intendo negli ultimi due punti, basta osservare che una curva del tipo utilizzato nel nostro modello cubico ha, più o meno, una forma come in figura . Un modello cubico in azione... Certamente tutto questo sostiene quanto detto da Trump a suo tempo che l’epidemia “scomparirà come fosse un miracolo”, ma aspettarsi che i morti tornino in vita è forse un po’ esagerato persino per lui. Ed è evidente che un modello che è sicuramente completamente sbagliato in 2 settimane, non ha alcun valore predittivo a una settimana. . Ma il problema grave è che stiamo parlando di un organo di stato ufficiale che spara idiozie spacciandole per certezze. . Palle cubiche, appunto. . Elon Musk con un solo tweet ha prodotto miliardi di dollari di danni a Tesla, ma qui si tratta di persone che moriranno a causa di questo tweet. . Questo non è e non può essere accettabile. . M. . PS: non posso esimermi dal ricordare che anche in Italia alcuni economisti hanno a suo tempo previsto zero contagi per questa settimana (e a quanto pare in Piemonte non ci sono più contagi già da 2 o 3 settimane, si vede che ci siamo sbagliati tutti). A onor del vero, all’inizio gli autori hanno sottolineato come la loro fosse una semplice analisi da non usare in senso predittivo. Ma con l’attenzione mediatica (e il Corriere è responsabile in questo caso) l’iniziale cautela è stata presto abbandonata. .",
            "url": "https://datacasual.com/italian/covid19/2020/05/06/palle-cubiche.html",
            "relUrl": "/italian/covid19/2020/05/06/palle-cubiche.html",
            "date": " • May 6, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Tutti in maschera? La scienza dice sì",
            "content": "Tradotto dall’originale del prof. Trisha Greenhalgh OBE e di Jeremy Howard . Non sapete cosa pensare a proposito delle mascherine? Certo, è una questione complicata, ma meno di quanto alcuni lascino intendere. Abbiamo esaminato la scienza disponibile (cfr. il nostro articolo Face Masks Against COVID-19: An Evidence Review — con non meno di 84 riferimenti bibliografici! — e Face masks for the public during the covid-19 crisis). In questo post riassiumiamo il punto di vista di diverse aree di ricerca, con la nostra interpretazione della faccenda. . L’epidemiologia della diffusione della malattia . Se frequentate internet anche sporadicamente, quasi sicuramente avrete visto video con trappole per topi o pezzi di domino, dove un solo evento scatena una gigantesca reazione a catena. Più vicini sono i pezzi del domino (o le trappole per topi), più la reazione è caotica. Ogni malattia infettiva ha un coefficiente di trasmissione (R0); se questo coefficiente è esattamente 1, vuol dire che ogni persona infetta, in media, contagia un’altra persona. Una malattia con R0 minore di 1 scompare nel tempo. La variante dell’influenza che ha causato la pandemia del 1918 aveva un R0 di 1,8. Per il virus che causa COVID-19 R0 è stato stimato intorno a 2,4 dai ricercatori dell’Imperial College di Londra, ma alcune ricerche suggeriscono che potrebbe addirittura arrivare a 5,7. Questo vuol dire che senza misure di contenimento, COVID-19 si diffonde moltissimo e in maniera molto rapida. Soprattutto, i pazienti con COVID-19 sono contagiosi soprattutto negli stadi iniziali della malattia (To et al. 2020; Zou et al. 2020; Bai et al. 2020; Zhang et al. 2020; Doremalen et al. 2020; Wei 2020), quando spesso presentano pochi o nessun sintomo. . La fisica delle goccioline e degli aerosol . Quando parliamo, minuscole goccioline vengono espulse dalla bocca. Nel caso in cui una persona sia infetta, queste goccioline contengono virus. Solo le goccioline più grandi durano più di un decimo di secondo prima di evaporare e trasformarsi in “nuclei”, 3-5 volte più piccoli della goccia originale, ma ancora contenenti virus (Wells 1934; Duguid 1946; Morawska et al. 2009). . Questo vuol dire che è molto più semplice bloccare le goccioline appena fuori dalla bocca, quando sono molto più grandi, piuttosto che bloccarle quando raggiungono la faccia e le mucose di una persona non contagiata che viene colpita dalle goccioline in questione. Ma per qualche motivo, questo non è quello su cui gran parte dei ricercatori si è concentrata… . Mascherine e scienze dei materiali . I dibattiti sull’efficacia delle mascherine spesso partono dal presupposto che lo scopo della mascherina è di proteggere chi la indossa, visto che è quello su cui ci si concentra e si insegna durante la formazione dei medici. In questo le mascherine di stoffa offrono una protezione scadente (pur non essendo del tutto inutili). Per avere una protezione del 100%, chi indossa la mascherina deve avere un respiratore medico (tipo N95) adeguatamente indossato. Ma mascherine di stoffa, indossate da una persona infetta, sono estremamente efficaci nel proteggere le persone circostanti. Questo, in inglese, è detto “source control”, ovvero “controllo alla fonte”. Ed è il controllo alla fonte quello di cui si parla (o di cui si dovrebbe parlare) nel dibattito sulle mascherine per il pubblico. . Se una persona con COVID-19 tossisce su qualcuno a una ventina di centimetri di distanza, una mascherina di cotone riduce la quantità di virus trasmessa all’altra persona di 36 volte, ed è persino più efficace di una mascherina chirurgica. Curiosamente, i ricercatori che hanno scoperto questa cosa hanno considerato questa riduzione di 36 volte “inefficace”. Noi non siamo d’accordo. Vuol dire trasmettere solamente un 36mo della quantità di virus trasmessa altrimenti, diminuendo la carica virale, con una conseguente probabile riduzione della probabilità di contagio e sintomi più lievi se il contagio avviene. . La matematica della trasmissione del virus . I modelli matematici sviluppati dal nostro team, supportati da altra ricerca (Yan et al. 2019), suggeriscono che se la maggior parte delle persone indossano mascherine in pubblico, il fattore di trasmissione (“R effettivo”), può scendere sotto 1, arrestando la diffusione del virus. La mascherina non deve bloccare ogni singolo virus, ma più ne blocca, più basso è il valore effettivo di R. . Modello dell&#39;impatto dell&#39;uso delle mascherine sul fattore di riproduzione Quanto la diffusione delle mascherine sia efficace dipende da tre fattori illustrati dal diagramma: quanto la maschera blocca il virus (“Efficacy”: l’asse orizzontale), la percentuale della popolazione che indossa le maschere (“Adherence”: l’asse verticale), e il fattore di trasmissione della malattia (R0: le linee nere nel grafico). L’area in blu del diagramma indica un R0 minore di 1, necessario per sconfiggere l’epidemia. Anche se le maschere dovessero bloccare una porzione molto più piccola di particelle virali, la malattia potrebbe comunque essere controllata, ma l’intera popolazione o quasi dovrebbe indossare maschere. . Mascherine e scienze politiche . Come si può far sì che tutti o comunque la maggioranza delle persone indossino maschere? Beh, si può educarle e cercare di convincerle, ma un approccio più efficace è imporre che tutti indossino mascherine, che sia in contesti specifici come sui trasporti pubblici o nei negozi alimentari, o ancor meglio per qualunque motivo si esca da casa. La ricerca sui vaccini (Bradford and Mandich 2015) mostra che nelle aree in cui l’esenzione dai vaccini segue restrizioni più severe, si ha una copertura vaccinale sensibilimente più alta. Lo stesso approccio sta ora venendo utilizzato per ottenere un’adozione più vasta delle mascherine, e risultati preliminari (Leffler et al. 2020) indicano che leggi in tal senso sono efficaci nel migliorare il rispetto della misura e stanno rallentando se non fermando la diffusione di COVID-19. . Esperimenti con le maschere: artificiali e naturali . Un esperimento artificiale si ha quando un ricercatore divide un campione di persone (solitamente a caso, da cui il termine “sperimentazione controllata randomizzata” – randomized controlled trial) in un gruppo che indossa mascherine e un gruppo che non le indossa (il cosiddetto gruppo di controllo). Non ci sono state sperimentazioni controllate randomizzate sull’uso delle mascherine nella popolazione generale nel caso di COVID-19. Sperimentazioni controllate randomizzate nella prevenzione di altre malattie (come l’influenza e la tubercolosi) con l’uso delle mascherine hanno tendenzialmente mostrato un effetto limitato e in molti casi non statisticamente significativo. In molti di questi studi, i soggetti assegnati al gruppo delle mascherine non sempre hanno indossato le mascherine. . Un esperimento naturale è quando si studia qualcosa che accade al di fuori di un contesto controllato – ad esempio quando una nazione introduce una misura per incrementare l’utilizzo delle mascherine. La Corea del Sud, ad esempio, ha avuto una diffusione interna di COVID-19 che nelle settimane iniziali ha seguito la traiettoria dell’Italia. Verso la fine di febbraio, il governo ha cominciato a fornire una scorta regolare di mascherine a tutti i cittadini. Da quel momento tutto è cambiato. Mentre il numero di morti giornalieri in Italia ha cominciato a crescere a livelli terrificanti, quello della Corea del Sud ha invece cominciato non solo a crescere di meno, ma a diminuire. Questo è il numero di casi attivi in Corea del Sud (in rosso) e in Italia (in blu); osservate cosa succede a inizio marzo, quando la distribuzione delle mascherine ha cominciato a fare effetto (questa analisi è stata fatta da Hyokon Zhiang la visualizzazione da Reshama Shaik): . Paragone dei casi di COVID-19 tra Corea del Sud e Italia Gli esperimenti naturali sono scientificamente imperfetti, perché non c’è gruppo di controllo, quindi non possiamo affermare che alcun cambiamento sia dovuto alle mascherine. Alcune nazioni che hanno introdotto una politica sulle mascherine, hanno introdotto più o meno allo stesso tempo altre misure come un rigido distanziamento sociale, la chiusura delle scuole e la cancellazione degli eventi pubblici. Persino in quei casi, però, si possono trovare paragoni interessanti. Ad esempio, l’Austria e la confinante Repubblica Ceca hanno introdotto misure di distanziamento sociale nella stesso giorno, ma la Repubblica Ceca ha introdotto anche l’obbligo di indossare mascherine. In Austria l’infezione ha continuato a peggiorare, mentre in Repubblica Ceca si è appiattita. Finché l’Austria ha introdotto leggi sulle mascherine qualche settimana più tardi e le due nazioni sono tornate su traiettorie simili. . Paragone dei casi di COVID-19 tra Repubblica Ceca e Austria Soprattutto: indipendentemente dal momento, in tutte le nazioni dove l’uso delle mascherine è stato incoraggiato per legge, o in cui le mascherine sono state distribuite alla popolazione, il numero di casi e di morti giornalieri è precipitato. . Mascherine e scienze comportamentali . Alcuni sostengono (Brosseau et al. 2020) che costringere o incoraggiare le persone a indossare mascherine incoraggerebbe comportamenti rischiosi nella popolazione (ad esempio, uscire di più o lavarsi le mani di meno), con un risultato netto negativo, come osservato in alcuni controlli sperimentali con le mascherine. Alcune argomentazioni simili sono state usate contro l’adozione di strategie di prevenzione per HIV (Cassell et al. 2006; Rojas Castro, Delabre, and Molina 2019) o leggi per l’obbligo dei caschi sui motocicli (Ouellet 2011). Tuttavia, la ricerca sul campo in questi ambiti ha evidenziato che anche se alcuni individui rispondono con un comportamento rischioso, a livello di popolazione si osserva un miglioramento della sicurezza e del benessere (Peng et al. 2017; Houston and Richardson 2007). . Mascherine ed economia . Alcune analisi economiche hanno confrontato il costo di distribuire mascherine con il valore (economico e non) che si potrebbe ottenere – o potenzialmente perdere – se fossero distribuite. Questi studi economici (Abaluck et al. 2020) indicano che ogni maschera indossata da una persona (che ha un costo praticamente nullo) potrebbe generare benefici economici di migliaia di dollari e salvare molte vite. . Mascherine e antropologia . Indossare mascherine in pubblico è diventata una cosa normale in molte nazioni asiatiche, sia per motivi individuali (per proteggersi dall’inquinamento) che collettivi (come risultato delle recenti epidemie di MERS e SARS). La mia mascherina ti protegge, la tua mascherina mi protegge. Nella maggioranza di queste nazioni, però, la norma era di indossare mascherine solo quando si presentano dei sintomi; solo nelle ultime settimane, con l’aumentare della consapevolezza sui contagi da parte di asintomatici, l’abitudine di indossare le maschere a prescindere dai sintomi si è diffusa. . Conclusioni . Anche se non tutte le evidenze scientifiche supportano la diffusione delle mascherine, la maggior parte puntano nella stessa direzione. Il nostro esame delle evidenze disponibili ci ha portato a una conclusione chiara: tenetevi le vostre goccioline – indossate mascherine. . Non è difficile farsele da soli con una maglietta, un fazzoletto, un pezzo di carta da cucina o anche semplicemente indossando una sciarpa o una bandana sulla faccia. Idealmente, utilizzate un tessuto stretto che permette di respirare. I ricercatori raccomandano di includere uno strato di carta da cucina o un filtro usa e getta; potete semplicemente aggiungerlo tra due strati di tessuto. Non c’è alcuna evidenza che una mascherina debba essere fatta con mezzi speciali per essere efficace nel controllo alla fonte. Una mascherina di stoffa può essere lavata e riutilizzata, proprio come una maglietta. . A quanto pare, se state incubando COVID-19, le persone a cui tenete vi saranno grate per aver indossato una mascherina. . Epilogo: Jeremy mostra come funziona il controllo alla fonte . Ecco un piccolo esperimento di Jeremy sul controllo alla fonte! . Riferimenti . Abaluck, Jason, Judith A. Chevalier, Nicholas A. Christakis, Howard Paul Forman, Edward H. Kaplan, Albert Ko, and Sten H. Vermund. 2020. “The Case for Universal Cloth Mask Adoption and Policies to Increase Supply of Medical Masks for Health Workers.” SSRN Scholarly Paper ID 3567438. Rochester, NY: Social Science Research Network. https://papers.ssrn.com/abstract=3567438. | Bai, Yan, Lingsheng Yao, Tao Wei, Fei Tian, Dong-Yan Jin, Lijuan Chen, and Meiyun Wang. 2020. “Presumed Asymptomatic Carrier Transmission of Covid-19.” Jama. | Bradford, W David, and Anne Mandich. 2015. “Some State Vaccination Laws Contribute to Greater Exemption Rates and Disease Outbreaks in the United States.” Health Affairs 34 (8): 1383–90. | Brosseau, Lisa M., ScD, Margaret Sietsema, PhD Apr 01, and 2020. 2020. “COMMENTARY: Masks-for-All for COVID-19 Not Based on Sound Data.” CIDRAP. https://www.cidrap.umn.edu/news-perspective/2020/04/commentary-masks-all-covid-19-not-based-sound-data. | Cassell, Michael M, Daniel T Halperin, James D Shelton, and David Stanton. 2006. “Risk Compensation: The Achilles’ Heel of Innovations in Hiv Prevention?” Bmj 332 (7541): 605–7. | Doremalen, Neeltje van, Trenton Bushmaker, Dylan H. Morris, Myndi G. Holbrook, Amandine Gamble, Brandi N. Williamson, Azaibi Tamin, et al. 2020. “Aerosol and Surface Stability of SARS-CoV-2 as Compared with SARS-CoV-1.” New England Journal of Medicine 0 (0): null. https://doi.org/10.1056/NEJMc2004973. | Duguid, JP. 1946. “The Size and the Duration of Air-Carriage of Respiratory Droplets and Droplet-Nuclei.” Epidemiology &amp; Infection 44 (6): 471–79. | Houston, David J, and Lilliard E Richardson. 2007. “Risk Compensation or Risk Reduction? Seatbelts, State Laws, and Traffic Fatalities.” Social Science Quarterly 88 (4): 913–36. | Leffler, Christopher, Edsel Ing, Craig A. McKeown, Dennis Pratt, and Andrzej Grzybowski. 2020. “Country-Wide Mortality from the Novel Coronavirus (COVID-19) Pandemic and Notes Regarding Mask Usage by the Public.” | Morawska, LJGR, GR Johnson, ZD Ristovski, Megan Hargreaves, K Mengersen, Steve Corbett, Christopher Yu Hang Chao, Yuguo Li, and David Katoshevski. 2009. “Size Distribution and Sites of Origin of Droplets Expelled from the Human Respiratory Tract During Expiratory Activities.” Journal of Aerosol Science 40 (3): 256–69. | Ouellet, James V. 2011. “Helmet Use and Risk Compensation in Motorcycle Accidents.” Traffic Injury Prevention 12 (1): 71–81. | Peng, Yinan, Namita Vaidya, Ramona Finnie, Jeffrey Reynolds, Cristian Dumitru, Gibril Njie, Randy Elder, et al. 2017. “Universal Motorcycle Helmet Laws to Reduce Injuries: A Community Guide Systematic Review.” American Journal of Preventive Medicine 52 (6): 820–32. | Rojas Castro, Daniela, Rosemary M Delabre, and Jean-Michel Molina. 2019. “Give Prep a Chance: Moving on from the ‘Risk Compensation’ Concept.” Journal of the International AIDS Society 22: e25351. | To, Kelvin Kai-Wang, Owen Tak-Yin Tsang, Wai-Shing Leung, Anthony Raymond Tam, Tak-Chiu Wu, David Christopher Lung, Cyril Chik-Yan Yip, et al. 2020. “Temporal profiles of viral load in posterior oropharyngeal saliva samples and serum antibody responses during infection by SARS-CoV-2: an observational cohort study.” Lancet Infect. Dis. 0 (0). https://doi.org/10.1016/S1473-3099(20)30196-1. | Wei, Wycliffe E. 2020. “Presymptomatic Transmission of SARS-CoV-2 â€” Singapore, January 23â€“March 16, 2020.” MMWR. Morbidity and Mortality Weekly Report 69. https://doi.org/10.15585/mmwr.mm6914e1. | Wells, WF. 1934. “On Air-Borne Infection: Study Ii. Droplets and Droplet Nuclei.” American Journal of Epidemiology 20 (3): 611–18. | Yan, Jing, Suvajyoti Guha, Prasanna Hariharan, and Matthew Myers. 2019. “Modeling the Effectiveness of Respiratory Protective Devices in Reducing Influenza Outbreak.” Risk Analysis 39 (3): 647–61. https://doi.org/10.1111/risa.13181. | Zhang, Juanjuan, Maria Litvinova, Wei Wang, Yan Wang, Xiaowei Deng, Xinghui Chen, Mei Li, et al. 2020. “Evolving Epidemiology and Transmission Dynamics of Coronavirus Disease 2019 Outside Hubei Province, China: A Descriptive and Modelling Study.” The Lancet Infectious Diseases 0 (0). https://doi.org/10.1016/S1473-3099(20)30230-9. | Zou, Lirong, Feng Ruan, Mingxing Huang, Lijun Liang, Huitao Huang, Zhongsi Hong, Jianxiang Yu, et al. 2020. “SARS-CoV-2 Viral Load in Upper Respiratory Specimens of Infected Patients.” New England Journal of Medicine 382 (12): 1177–9. https://doi.org/10.1056/NEJMc2001737. | .",
            "url": "https://datacasual.com/italian/covid19/2020/04/19/tutti-in-maschera.html",
            "relUrl": "/italian/covid19/2020/04/19/tutti-in-maschera.html",
            "date": " • Apr 19, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "Private FastPages on Kubernetes",
            "content": "This post is the very reason I decided myself to go back to blogging. I managed to do something that I considered relatively trivial, but let others know about it in the Fast.ai forums it turned out not to be that obvious after all. And writing about it, I realised that not even a year ago, I wouldn’t have had the faintest idea of what I am talking about here. . Context . . If you are not part of a mid-large company IT department, the following paragraph might sound like a bunch of corporate lingo that makes no sense. It is not completely true, but if you have no idea what I am talking about, just skip it. As a mathematician turned knowledge engineer turned product manager turned data scientist with a pench for learning new stuff, one of the many hats I tend to wear quite often is that of knowledge sharer. Since in my current role I am helping setting up a federated team of data analysts, one of the problems we need to solve is breaking the information siloes among data people. This way we can avoid duplicate work and we can piggyback on each others’ research in order to extract more advanced insights. . Since I am a bit of a Fast.ai fanboy and I am using Jupyter a lot in my data work, when fast_template/FastPages was presented, I started thinking about how to deploy it for my use case. The main blocker was that GitHub pages are always public, even on private repos, which would have been a showstopper, as we don’t want to police a self serving tool to check that no important information is being shared publicly. . Summary (and/or TL;DR) . In order to deploy FastPages privately on a Kubernetes cluster you need to: . Change the branch to which the website built by Jekyll is pushed | Deploy a static webpage server (I used Nginx) with a Git-sync sidecar to keep the served site up to date | Makesure the sidecar can pull the fastpages repo with a read only deploy key | Expose the server internally with appropriate network policies and ingress configurations | While steps 1-3 are fairly straightforward, the last step depends heavily on your cluster configuration and policies. I will give a very high level description of what I did, but you will have to do your own research to make it work in your case. . Requirements . This guide is not too beginner friendly and it is not meant to be: since the risk of getting it wrong is exposing private information, you need to have some working knowledge of what you are doing or at least some way of making sure that you are not doing huge mistakes (like a SRE/DevOps person to review what you are doing). Other than that you need . Access and admin privileges to private GitHub repos | The ability of running GitHub actions on the private repos | A Kubernetes cluster set up with appropriate network policies and DNS | A namespace that can access the private GitHub repo. This is usually the case, but if your cluster is super locked down, it might not be possible | . Important: to make the deployment, you need to know your way around Kubernetes. You just need to know how to use it and deploy/manage resources into it, you don’t need cluster admin knowledge of any kind . Setting up FastPages . First of all you have to setup your FastPages repo. Just follow the latest instructions (keep in mind that the tool is under active development, so those might change quite often); this will trigger a GitHub action that will open a PR. Before following the instructions in the PR, there is a few things to do to avoid fastpages publishing private stuff by mistake. . Set a branch protection rule to make sure that at least two approving reviews are required to push to the gh-pages. This is because by default, as soon as something is pushed to the gh-pages branch, it gets published on GitHub pages. As far as I know, there is no way to prevent this behaviour. | Checkout into the branch that has been opened by the Setup action (the one that the open PR is attempting to merge into master) and modify the .github/workflows/ci.yaml from this yaml name: Deploy if: github.event_name == ‘push’ uses: peaceiris/actions-gh-pages@v3 with: deploy_key: $ publish_dir: ./_site to something like this (you can pick whatever branch name you want) yaml | name: Deploy if: github.event_name == ‘push’ uses: peaceiris/actions-gh-pages@v3 with: deploy_key: $ publish_branch: private-website-branch publish_dir: ./_site | . | After this you are can continue setting up the repo according to the instructions in the PR. . This is all that is needed on the FastPages side of things. . Gotchas and other optional steps . If you want the website to function in any useful way, you will have to set up an internal domain. How to do so depends heavily on how the DNS and network policies are setup in your Kubernetes cluster. If your domain is going to be, for example shiny.private.website, you want to make sure to that . Your CNAME file (so that the categories work properly, for example) contains shiny.private.website | The _config.yml file contains url: &quot;https://shiny.private.website&quot; # the base hostname &amp; protocol for your site, e.g. http://example.com baseurl: &quot;&quot; . | . Before you merge the setup PR (or right after that), it is also a good idea to create an upstream branch and to set its remote to the original FastPages repo, so that you can keep your deployment in sync with the development of FastPages. . Don’t do it later as I did. It’s a pain to solve the merge conflicts. . Deploying the server . Since Jekyll builds a complete static website and the github action pushes it to the branch we have set up in the step above, we only need something capable of serving it. I have used a basic Nginx alpine image, but there are probably a thousand different options. In order to avoid having to redeploy the server manually everytime, furthermore, we want to add a git-sync sidecar that pulls the website branch into the served folder of the Nginx container and keeps it up to date. There are a few possible variations but this is how more or less how the manifest would look like . apiVersion: apps/v1 kind: Deployment metadata: name: your-namespace spec: selector: matchLabels: app: fastpages replicas: 1 # You can set this to something higher if needed template: metadata: labels: app: fastpages spec: restartPolicy: Always securityContext: fsGroup: 65533 # to make SSH key readable containers: - name: fastpages image: nginx:alpine imagePullPolicy: Always volumeMounts: - name: site mountPath: /usr/share/nginx/html - mountPath: /etc/nginx/conf.d name: fastpages-conf ports: - containerPort: 80 protocol: TCP resources: limits: memory: 20Mi - name: git-sync image: k8s.gcr.io/git-sync imagePullPolicy: IfNotPresent env: - name: GIT_SYNC_REPO value: &quot;git@github.com:your-githubname/yourprivaterepo.git&quot; - name: GIT_SYNC_DEST value: &quot;www&quot; - name: GIT_SYNC_ROOT value: &quot;/site&quot; - name: GIT_SYNC_SSH value: &quot;true&quot; - name: GIT_SYNC_MAX_SYNC_FAILURES value: &quot;5&quot; resources: requests: cpu: 0m memory: 0Mi limits: memory: 200Mi securityContext: runAsUser: 65533 # git-sync user volumeMounts: - name: git-secret mountPath: /etc/git-secret - name: site mountPath: /site volumes: - name: site emptyDir: {} - configMap: defaultMode: 420 name: fastpages-conf name: fastpages-conf - name: git-secret secret: secretName: fastpages-git-ssh defaultMode: 0400 apiVersion: v1 kind: Service metadata: name: fastpages spec: selector: app: fastpages ports: - name: http protocol: TCP port: 80 targetPort: 80 apiVersion: v1 kind: ConfigMap metadata: name: fastpages-conf namespace: your-namespace data: default.conf: |- server { listen 80; server_name _; root /usr/share/nginx/html/www/; access_log /dev/stdout; } . Before deploying the above, generate a new SSH key pair and create a secret with the private key in your namespace called fastpages-git-ssh. After that use the public key of the pair to create a new read only deploy key on your FastPages repo. . Once all this is done, you can deploy the above and you webserver container should start happily. Sadly, you will not be able to access it yet if your namespace has properly set policies. . Important: Please be careful of how you manage your secrets, don’t put them on GitHub unencrypted and don’t do anything weird. . Making the server accessible . In order to be expose the served webpages there are probably a couple more resources to be deployed. Both of these are dependent on how your Kubernetes cluster has been set up, so there is not much I can do to help you. In order to make everything work you need . An Ingress to expose the HTTP route to the DNS and within the cluster | A Netork Policy to make sure that the deployed resources are allowed to communicate among them, if this is not already possible by default in your namespace | Once again, if you don’t knwo how to do this, you will have to consult your SRE/DevOps/SystemAdmin team or whoever is maintaining the cluster. Please don’t follow the advice of a random Data Scientist to set up network policies for potentially sensitive resources. . Parting thoughts . If you are reading this, you should at this point have a deployment, or know how to get a fastpages powered private website on your Kubernetes cluster. . I admit that the recipe is quite verbose,but depending on your experience with Kubernetes, these steps might be more or less familiar. If that is not the case, I hope you managed to at least get an idea of what is going on. .",
            "url": "https://datacasual.com/fastpages/kubernetes/2020/03/07/private-fastpages-on-kubernetes.html",
            "relUrl": "/fastpages/kubernetes/2020/03/07/private-fastpages-on-kubernetes.html",
            "date": " • Mar 7, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Hi there, I am Miko. . I am European, originally from Italy, currently residing in the UK after a decade or so of roaming around the continent. . I am a mathematician, turned to the dark side of of the “real world” with a few fruitless postdocs under my belt. . After a winding path that saw me being an intern, a knowledge/sales engineer, a product manager, I ended up in data science, learning a thing or two in the process. . Hi there, I am Miko, I’m an accidental data scientist and I learn things, because I like it and because I must. . Welcome to my site. . This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://datacasual.com/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

}